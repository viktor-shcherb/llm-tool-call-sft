run:
  output_dir: "checkpoints/car-sales-sft"
  seed: 42
  report_to: "wandb"

data:
  load_module: "car_sales"
  dataset_name: "Salesteq/car-sales-convos"
  timezone: "Europe/Zurich"
  sysprompt_path: "data/sysprompt.md"
  tools_path: "data/tool_calls.json"

  # context / tokenization
  tokenizer: "viktoroo/SmolLM2-360M-Tools"
  max_context_length: 8192
  drop_oversized: true
  n_tool_sessions_eval: 64             # for tool eval construction

model:
  base_model_name: "viktoroo/SmolLM2-360M-Tools"
  torch_dtype: "bfloat16"              # "bfloat16" or "float16" or "float32"

  pad_token_fallback: "eos"            # if no pad_token in tokenizer/model then copy eos

lora:
  r: 64
  alpha: 128
  dropout: 0.05
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj
  bias: "none"
  task_type: "CAUSAL_LM"

train:
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 8
  num_train_epochs: 3

  learning_rate: 0.0002        # 2e-4
  weight_decay: 0.0
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.03

  bf16: true
  fp16: false

  ddp_find_unused_parameters: false

  logging_steps: 10
  eval_strategy: "epoch"       # Trainer arg evaluation_strategy
  save_strategy: "epoch"       # Trainer arg save_strategy
  save_total_limit: 2
  overwrite_output_dir: false
  remove_unused_columns: false

eval:
  max_new_tokens_eval: 256
  temperature: 0.0
